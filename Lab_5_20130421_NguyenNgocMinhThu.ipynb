{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nguyen-Ngoc-Minh-Thu/ML2023_TV201/blob/main/Lab_5_20130421_NguyenNgocMinhThu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This lab is to deal with **SVM** to classification tasks and compare its performance with other competitive algorithms. In general, **SVM** is one of the most popular and widely used supervised machine learning algorithms.\n",
        "\n",
        "*   **Deadline: 23:59, 17/03/2023**\n",
        "\n"
      ],
      "metadata": {
        "id": "LMzehe0sy5wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "H4nJmxp9zGX4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DoVWQ8AEyc-C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01ad0d62-a3f2-4ce0-8bb4-23bc52d49804"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/ML\n"
          ]
        }
      ],
      "source": [
        "# code\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd '/content/gdrive/MyDrive/ML'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#import\n",
        "from prettytable import PrettyTable\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn import datasets\n",
        "from sklearn.datasets import load_digits\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "M0P5eLavrgMm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1. \n",
        "For breast cancer dataset (https://tinyurl.com/3vme8hr3) which could be loaded from datasets in sklearn as follows:\n",
        "\n",
        "```\n",
        "#Import scikit-learn dataset library\n",
        "from sklearn import datasets\n",
        "\n",
        "#Load dataset\n",
        "cancer = datasets.load_breast_cancer()\n",
        "```\n",
        "\n",
        "*   1.1.\tApply SVM algorithm to above dataset using linear kernel.\n",
        "*   1.2.\tCompare the obtained results with other competitive algorithms (Logistic Regression, Decision Tree, kNN) based on metrics: accuracy, precision, recall, f1 measures.\n",
        "\n"
      ],
      "metadata": {
        "id": "kNv07ARGzOUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "#load data\n",
        "cancer = datasets.load_breast_cancer()\n",
        "X = cancer.data\n",
        "y = cancer.target\n",
        "# chuan hoa data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y,test_size =0.3)\n",
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
        "#Train the model using the training sets\n",
        "clf.fit(X_train, y_train)\n",
        "#Predict the response for test dataset\n",
        "y_pred_svm = clf.predict(X_test)\n",
        "#logistic regression\n",
        "lg = LogisticRegression(max_iter=1000)\n",
        "lg.fit(X_train, y_train)\n",
        "y_pred_lg = lg.predict(X_test)\n",
        "#Knn Regression\n",
        "#k=1\n",
        "kNN = KNeighborsClassifier(n_neighbors=5)\n",
        "kNN.fit(X_train, y_train)\n",
        "y_pred_kNN = kNN.predict(X_test)\n",
        "#Decision Tree\n",
        "tree = DecisionTreeClassifier(criterion=\"gini\", random_state=42,\n",
        "max_depth=3, min_samples_leaf=5) \n",
        "tree.fit(X_train,y_train)\n",
        "y_predict_tree = tree.predict(X_test)\n",
        "\n",
        "# these 3 are the columns of the table\n",
        "t = PrettyTable([' ', 'accuracy','precision','recall','f1_score'])\n",
        "#To insert rows\n",
        "t.add_row(['SVM',accuracy_score(y_test, y_pred_svm),precision_score(y_test, y_pred_svm, average='macro'),recall_score(y_test, y_pred_svm, average='macro'),f1_score(y_test, y_pred_svm, average='macro')])\n",
        "t.add_row(['KNN',accuracy_score(y_test, y_pred_kNN), precision_score(y_test, y_pred_kNN, average='macro'),recall_score(y_test, y_pred_kNN, average='macro'),f1_score(y_test, y_pred_kNN, average='macro')])\n",
        "t.add_row(['Logistic Regression',accuracy_score(y_test, y_pred_lg), precision_score(y_test, y_pred_lg, average='macro'), recall_score(y_test, y_pred_lg, average='macro'),f1_score(y_test, y_pred_lg, average='macro')])\n",
        "t.add_row(['Decision Tree', accuracy_score(y_test, y_predict_tree),precision_score(y_test, y_predict_tree, average='macro'),recall_score(y_test, y_predict_tree, average='macro'),f1_score(y_test, y_predict_tree, average='macro')])\n",
        "print(t)\n"
      ],
      "metadata": {
        "id": "sOsg77IBzEyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceb81909-c338-496e-8dac-34f1071b1454"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                     |      accuracy      |     precision      |       recall       |      f1_score      |\n",
            "+---------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|         SVM         | 0.9824561403508771 | 0.9863636363636363 |     0.9765625      | 0.9810875576036866 |\n",
            "|         KNN         | 0.9766081871345029 | 0.9819819819819819 |      0.96875       |  0.97469665581533  |\n",
            "| Logistic Regression | 0.9824561403508771 | 0.9863636363636363 |     0.9765625      | 0.9810875576036866 |\n",
            "|    Decision Tree    | 0.9473684210526315 | 0.9426705370101597 | 0.9453855140186915 | 0.9439895185063871 |\n",
            "+---------------------+--------------------+--------------------+--------------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2. \n",
        "\n",
        "*   1.1.\tPerform SVM algorithm to **Iris dataset** using **linear kernel**.\n",
        "*   1.2.\tCompare the obtained results in 1.1 with SVM using other kernels (**Polynomial Kernel, Gaussian Kernel, Sigmoid Kernel, Radial Basis Function Kernel**). Some metrics could be used: accuracy, precision, recall, f1 measures\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S43IoUT-0OQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "#load data\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "#chuan hoa data\n",
        "scaler = StandardScaler()\n",
        "X_scaler = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaler, y, test_size = 0.3)\n",
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
        "#Train the model using the training sets\n",
        "clf.fit(X_train, y_train)\n",
        "#Predict the response for test dataset\n",
        "y_pred_linear = clf.predict(X_test)\n",
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel='poly') # Polynomial Kernel\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred_poly = clf.predict(X_test)\n",
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel='rbf') # Radial Basis Function Kernel\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred_rbf = clf.predict(X_test)\n",
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel='sigmoid') # Sigmoid Kernel\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred_sigmoid = clf.predict(X_test)\n",
        "\n",
        "t = PrettyTable([' ', 'accuracy','precision','recall','f1_score'])\n",
        "#To insert rows\n",
        "t.add_row(['Linear',accuracy_score(y_test, y_pred_linear),precision_score(y_test, y_pred_linear, average='macro'),recall_score(y_test, y_pred_linear, average='macro'),f1_score(y_test, y_pred_linear, average='macro')])\n",
        "t.add_row(['Polynomial',accuracy_score(y_test, y_pred_poly), precision_score(y_test, y_pred_poly, average='macro'),recall_score(y_test, y_pred_poly, average='macro'),f1_score(y_test, y_pred_poly, average='macro')])\n",
        "t.add_row(['Radial Basis Function',accuracy_score(y_test, y_pred_rbf), precision_score(y_test, y_pred_rbf, average='macro'), recall_score(y_test, y_pred_rbf, average='macro'),f1_score(y_test, y_pred_rbf, average='macro')])\n",
        "t.add_row(['Sigmoid', accuracy_score(y_test, y_pred_sigmoid),precision_score(y_test, y_pred_sigmoid, average='macro'),recall_score(y_test, y_pred_sigmoid, average='macro'),f1_score(y_test, y_pred_sigmoid, average='macro')])\n",
        "print(t)"
      ],
      "metadata": {
        "id": "_xhPpF5b033h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02a6cfc3-2e5f-4527-958f-645015b40aff"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                       |      accuracy      |     precision      |       recall       |      f1_score      |\n",
            "+-----------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|         Linear        | 0.9777777777777777 | 0.9803921568627452 | 0.9696969696969697 | 0.9740259740259741 |\n",
            "|       Polynomial      | 0.9333333333333333 | 0.9285714285714285 |       0.9375       | 0.9255172413793104 |\n",
            "| Radial Basis Function | 0.9777777777777777 | 0.9803921568627452 | 0.9696969696969697 | 0.9740259740259741 |\n",
            "|        Sigmoid        | 0.9111111111111111 | 0.9001782531194297 | 0.9000420875420875 | 0.8995670995670996 |\n",
            "+-----------------------+--------------------+--------------------+--------------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 3. \n",
        "Compare the performance of selected classification algorithms (Decision Tree, kNN, Logistic Regression) and SVM (using different kernels) with mnist dataset based on accuracy, precision, recall, f1 measures.\n"
      ],
      "metadata": {
        "id": "b52OPWPD2afi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "#load data\n",
        "mnist = datasets.load_digits()\n",
        "X = mnist.data\n",
        "y = mnist.target\n",
        "# chuan hoa data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y,test_size =0.3)\n",
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
        "#Train the model using the training sets\n",
        "clf.fit(X_train, y_train)\n",
        "#Predict the response for test dataset\n",
        "y_pred_linear = clf.predict(X_test)\n",
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel='poly') # Polynomial Kernel\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred_poly = clf.predict(X_test)\n",
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel='rbf') # Radial Basis Function Kernel\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred_rbf = clf.predict(X_test)\n",
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel='sigmoid') # Sigmoid Kernel\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred_sigmoid = clf.predict(X_test)\n",
        "#logistic regression\n",
        "lg = LogisticRegression(max_iter=1000)\n",
        "lg.fit(X_train, y_train)\n",
        "y_pred_lg = lg.predict(X_test)\n",
        "#Knn Regression\n",
        "#k=1\n",
        "kNN = KNeighborsClassifier(n_neighbors=5)\n",
        "kNN.fit(X_train, y_train)\n",
        "y_pred_kNN = kNN.predict(X_test)\n",
        "#Decision Tree\n",
        "tree = DecisionTreeClassifier(criterion=\"gini\", random_state=42,\n",
        "max_depth=3, min_samples_leaf=5) \n",
        "tree.fit(X_train,y_train)\n",
        "y_predict_tree = tree.predict(X_test)\n",
        "\n",
        "t = PrettyTable([' ', 'accuracy','precision','recall','f1_score'])\n",
        "#To insert rows\n",
        "t.add_row(['Linear',accuracy_score(y_test, y_pred_linear),precision_score(y_test, y_pred_linear, average='macro',zero_division=1),recall_score(y_test, y_pred_linear, average='macro'),f1_score(y_test, y_pred_linear, average='macro')])\n",
        "t.add_row(['Polynomial',accuracy_score(y_test, y_pred_poly), precision_score(y_test, y_pred_poly, average='macro', zero_division=1),recall_score(y_test, y_pred_poly, average='macro'),f1_score(y_test, y_pred_poly, average='macro')])\n",
        "t.add_row(['Radial Basis Function',accuracy_score(y_test, y_pred_rbf), precision_score(y_test, y_pred_rbf, average='macro', zero_division=1), recall_score(y_test, y_pred_rbf, average='macro'),f1_score(y_test, y_pred_rbf, average='macro')])\n",
        "t.add_row(['Sigmoid', accuracy_score(y_test, y_pred_sigmoid),precision_score(y_test, y_pred_sigmoid, average='macro', zero_division=1),recall_score(y_test, y_pred_sigmoid, average='macro'),f1_score(y_test, y_pred_sigmoid, average='macro')])\n",
        "t.add_row(['KNN',accuracy_score(y_test, y_pred_kNN), precision_score(y_test, y_pred_kNN, average='macro', zero_division=1),recall_score(y_test, y_pred_kNN, average='macro'),f1_score(y_test, y_pred_kNN, average='macro')])\n",
        "t.add_row(['Logistic Regression',accuracy_score(y_test, y_pred_lg), precision_score(y_test, y_pred_lg, average='macro', zero_division=1), recall_score(y_test, y_pred_lg, average='macro'),f1_score(y_test, y_pred_lg, average='macro')])\n",
        "t.add_row(['Decision Tree', accuracy_score(y_test, y_predict_tree),precision_score(y_test, y_predict_tree, average='macro', zero_division=1),recall_score(y_test, y_predict_tree, average='macro'),f1_score(y_test, y_predict_tree, average='macro')])\n",
        "print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-9jFbxrG0m5",
        "outputId": "ba9a4291-b179-44d2-9cd2-cd2a15409472"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------+---------------------+--------------------+---------------------+---------------------+\n",
            "|                       |       accuracy      |     precision      |        recall       |       f1_score      |\n",
            "+-----------------------+---------------------+--------------------+---------------------+---------------------+\n",
            "|         Linear        |  0.9648148148148148 | 0.965826641262743  |  0.9650781720410876 |  0.9651822147548907 |\n",
            "|       Polynomial      |  0.9407407407407408 | 0.9570867263656269 |  0.9419947587888131 |  0.9458446919055763 |\n",
            "| Radial Basis Function |  0.9740740740740741 | 0.9754531901202986 |  0.9749795902552512 |  0.9749489920100354 |\n",
            "|        Sigmoid        |  0.9537037037037037 | 0.952239438112176  |  0.9533288007517771 |  0.9524649402772113 |\n",
            "|          KNN          |  0.9685185185185186 | 0.9680920788323164 |  0.969993752449646  |  0.9686697690158314 |\n",
            "|  Logistic Regression  |  0.9537037037037037 | 0.956974702898705  |  0.9565333699229159 |  0.9562576927997778 |\n",
            "|     Decision Tree     | 0.42777777777777776 | 0.7006928486074088 | 0.44600622768976494 | 0.35765303311503793 |\n",
            "+-----------------------+---------------------+--------------------+---------------------+---------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4. \n",
        "Compare the performance of selected classification algorithms (Decision Tree, kNN, Logistic Regression) and SVM (using different kernels) with **credit card dataset** based on accuracy, precision, recall, f1 measures.\n",
        "\n",
        "*   Give some comments on the obtained results\n",
        "*   Identify issues with dataset, and propose the solutions to these issues\n",
        "\n"
      ],
      "metadata": {
        "id": "Z5pp7_h-aP2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "dataSet = pd.read_csv(\"creditcard.csv\")\n",
        "dataSet = dataSet.head(10000)\n",
        "X = dataSet.drop('Class', axis =1)\n",
        "y = dataSet['Class']\n",
        "#Chuan hoa du lieu\n",
        "scaler = StandardScaler()\n",
        "X_scaler = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaler, y, test_size = 0.3)\n",
        "\n",
        "#logistic regression\n",
        "lg = LogisticRegression(max_iter=1000)\n",
        "lg.fit(X_train, y_train)\n",
        "y_pred_lg = lg.predict(X_test)\n",
        "#Knn Regression\n",
        "#k=1\n",
        "kNN = KNeighborsClassifier(n_neighbors=5)\n",
        "kNN.fit(X_train, y_train)\n",
        "y_pred_kNN = kNN.predict(X_test)\n",
        "#Decision Tree\n",
        "tree = DecisionTreeClassifier(criterion=\"gini\", random_state=42,\n",
        "max_depth=3, min_samples_leaf=5) \n",
        "tree.fit(X_train,y_train)\n",
        "y_predict_tree = tree.predict(X_test)\n",
        "\n",
        "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
        "#Train the model using the training sets\n",
        "clf.fit(X_train, y_train)\n",
        "#Predict the response for test dataset\n",
        "y_pred_linear = clf.predict(X_test)\n",
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel='poly') # Polynomial Kernel\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred_poly = clf.predict(X_test)\n",
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel='rbf') # Radial Basis Function Kernel\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred_rbf = clf.predict(X_test)\n",
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel='sigmoid') # Sigmoid Kernel\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred_sigmoid = clf.predict(X_test)\n",
        "\n",
        "t = PrettyTable([' ', 'accuracy','precision','recall','f1_score'])\n",
        "#To insert rows\n",
        "t.add_row(['Linear',accuracy_score(y_test, y_pred_linear),precision_score(y_test, y_pred_linear, average='macro',zero_division=1),recall_score(y_test, y_pred_linear, average='macro'),f1_score(y_test, y_pred_linear, average='macro')])\n",
        "t.add_row(['Polynomial',accuracy_score(y_test, y_pred_poly), precision_score(y_test, y_pred_poly, average='macro', zero_division=1),recall_score(y_test, y_pred_poly, average='macro'),f1_score(y_test, y_pred_poly, average='macro')])\n",
        "t.add_row(['Radial Basis Function',accuracy_score(y_test, y_pred_rbf), precision_score(y_test, y_pred_rbf, average='macro', zero_division=1), recall_score(y_test, y_pred_rbf, average='macro'),f1_score(y_test, y_pred_rbf, average='macro')])\n",
        "t.add_row(['Sigmoid', accuracy_score(y_test, y_pred_sigmoid),precision_score(y_test, y_pred_sigmoid, average='macro', zero_division=1),recall_score(y_test, y_pred_sigmoid, average='macro'),f1_score(y_test, y_pred_sigmoid, average='macro')])\n",
        "t.add_row(['KNN',accuracy_score(y_test, y_pred_kNN), precision_score(y_test, y_pred_kNN, average='macro', zero_division=1),recall_score(y_test, y_pred_kNN, average='macro'),f1_score(y_test, y_pred_kNN, average='macro')])\n",
        "t.add_row(['Logistic Regression',accuracy_score(y_test, y_pred_lg), precision_score(y_test, y_pred_lg, average='macro', zero_division=1), recall_score(y_test, y_pred_lg, average='macro'),f1_score(y_test, y_pred_lg, average='macro')])\n",
        "t.add_row(['Decision Tree', accuracy_score(y_test, y_predict_tree),precision_score(y_test, y_predict_tree, average='macro', zero_division=1),recall_score(y_test, y_predict_tree, average='macro'),f1_score(y_test, y_predict_tree, average='macro')])\n",
        "print(t)\n"
      ],
      "metadata": {
        "id": "Rw_-8FIf2KxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19b56984-1cba-44ae-c679-a1584a097291"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                       |      accuracy      |     precision      |       recall       |      f1_score      |\n",
            "+-----------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|         Linear        | 0.9993333333333333 | 0.9166666666666667 | 0.9996655518394648 | 0.9543781745186897 |\n",
            "|       Polynomial      | 0.9993333333333333 | 0.9996657754010696 |        0.9         | 0.9442772762732643 |\n",
            "| Radial Basis Function | 0.9993333333333333 | 0.9996657754010696 |        0.9         | 0.9442772762732643 |\n",
            "|        Sigmoid        | 0.9996666666666667 | 0.9998328318288198 |        0.95        | 0.9736006124657908 |\n",
            "|          KNN          | 0.9996666666666667 | 0.9998328318288198 |        0.95        | 0.9736006124657908 |\n",
            "|  Logistic Regression  |        1.0         |        1.0         |        1.0         |        1.0         |\n",
            "|     Decision Tree     | 0.9996666666666667 | 0.9998328318288198 |        0.95        | 0.9736006124657908 |\n",
            "+-----------------------+--------------------+--------------------+--------------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ],
      "metadata": {
        "id": "Ok7RGkea_b7n"
      }
    }
  ]
}